{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c64c54b-d8c4-4a47-b925-f2ff86d24a1c",
   "metadata": {
    "id": "9c64c54b-d8c4-4a47-b925-f2ff86d24a1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_cuda_availability():\n",
    "    \"\"\"\n",
    "    Checks if CUDA is available o the system.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if CUDA is available, False otherwise.\n",
    "    \"\"\"\n",
    "    return torch.cuda.is_available()\n",
    "\n",
    "check_cuda_availability()\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c680ee8c-7787-4519-a65d-c14b7d6be7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from transformers import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.set_verbosity_error()\n",
    "\"\"\"\n",
    "This script disables warnings and sets the logging verbosity to error level.\n",
    "\n",
    "Warnings are filtered out to avoid cluttering the output with non-critical messages.\n",
    "The logging verbosity is set to error level to only display error messages.\n",
    "\n",
    "This script is typically used in situations where warnings are not relevant or can be safely ignored.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef57afcd-b15f-4233-8abd-7c0bd3538957",
   "metadata": {
    "id": "ef57afcd-b15f-4233-8abd-7c0bd3538957"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "MegguFCgzH9s",
   "metadata": {
    "id": "MegguFCgzH9s"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import DistilBertForQuestionAnswering, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aU6UWuZG60Y-",
   "metadata": {
    "id": "aU6UWuZG60Y-"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 3\n",
    "learning_rate = 2e-5\n",
    "# create a dataframe with sample data\n",
    "df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35], 'Gender': ['F', 'M', 'M']})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tZdbkbKQ5X7C",
   "metadata": {
    "id": "tZdbkbKQ5X7C"
   },
   "outputs": [],
   "source": [
    "class SQuAD_Data(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the class.\n",
    "\n",
    "        Parameters:\n",
    "        - file_path (str): The path to the file containing the data.\n",
    "\n",
    "        Attributes:\n",
    "        - context_list (list): A list to store the context strings.\n",
    "        - question_list (list): A list to store the question strings.\n",
    "        - answer_list (list): A list to store the answer strings.\n",
    "        - start_pos_list (list): A list to store the start positions of the answers.\n",
    "        - end_pos_list (list): A list to store the end positions of the answers.\n",
    "        \"\"\"\n",
    "        self.context_list = []\n",
    "        self.question_list = []\n",
    "        self.answer_list = []\n",
    "        self.start_pos_list = []\n",
    "        self.end_pos_list = []\n",
    "        with open(file_path, 'r', encoding='cp1252') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            for row in reader:\n",
    "                self.context_list.append(row[0])\n",
    "                self.question_list.append(row[1])\n",
    "                self.answer_list.append(row[2])\n",
    "                self.start_pos_list.append(int(row[3]))\n",
    "                self.end_pos_list.append(int(row[4]))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "        - int: The number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.context_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the sample at the given index.\n",
    "\n",
    "        Parameters:\n",
    "        - idx (int): The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "        - dict: A dictionary containing the context, question, answer, start position, and end position of the sample.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'context': self.context_list[idx],\n",
    "            'question': self.question_list[idx],\n",
    "            'answer': self.answer_list[idx],\n",
    "            'start_pos': self.start_pos_list[idx],\n",
    "            'end_pos': self.end_pos_list[idx]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1269b23b-da52-43a8-850b-403a321f97c0",
   "metadata": {
    "id": "1269b23b-da52-43a8-850b-403a321f97c0",
    "outputId": "61aee01f-9225-439e-8471-7cbb359b9e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 37079\n",
      "Training loader size: 4635\n",
      "Testing dataset size: 5351\n",
      "Testing loader size: 669\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loads the SQuAD dataset and creates data loaders for training and testing.\n",
    "\n",
    "    Returns:\n",
    "        train_dl (DataLoader): DataLoader for the training dataset.\n",
    "        test_dl (DataLoader): DataLoader for the testing dataset.\n",
    "        ds_size (int): Size of the training dataset.\n",
    "        dl_size (int): Size of the training data loader.\n",
    "        ds_test_size (int): Size of the testing dataset.\n",
    "        dl_test_size (int): Size of the testing data loader.\n",
    "    \"\"\"\n",
    "    train_ds = SQuAD_Data('squad_train_data.csv')\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    ds_size = len(train_ds)\n",
    "    dl_size = len(train_dl)\n",
    "\n",
    "    test_ds = SQuAD_Data('squad_test_data.csv')\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "    ds_test_size = len(test_ds)\n",
    "    dl_test_size = len(test_dl)\n",
    "\n",
    "    return train_dl, test_dl, ds_size, dl_size, ds_test_size, dl_test_size\n",
    "\n",
    "train_dl, test_dl, ds_size, dl_size, ds_test_size, dl_test_size = load_data()\n",
    "\n",
    "print(f'Training dataset size: {ds_size}')\n",
    "print(f'Training loader size: {dl_size}')\n",
    "print(f'Testing dataset size: {ds_test_size}')\n",
    "print(f'Testing loader size: {dl_test_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "UmLrhnqr9L52",
   "metadata": {
    "id": "UmLrhnqr9L52"
   },
   "outputs": [],
   "source": [
    "def train_fn(train_model, data_ld, optim, device, acc_steps, tokenizer):\n",
    "    \"\"\"\n",
    "    Trains the model on the given data loader.\n",
    "\n",
    "    Args:\n",
    "        train_model (nn.Module): The model to be trained.\n",
    "        data_ld (DataLoader): The data loader containing the training data.\n",
    "        optim (Optimizer): The optimizer used for training.\n",
    "        device (str): The device to be used for training (e.g., 'cuda', 'cpu').\n",
    "        acc_steps (int): The number of gradient accumulation steps.\n",
    "        tokenizer (Tokenizer): The tokenizer used for encoding the input data.\n",
    "\n",
    "    Returns:\n",
    "        float: The average training loss per data point.\n",
    "    \"\"\"\n",
    "    train_model.train()\n",
    "    train_model.to(device)\n",
    "    t_loss = 0\n",
    "    scaler_object = GradScaler() \n",
    "    batch_count = 0\n",
    "    for data in data_ld:\n",
    "        inputs = tokenizer(\n",
    "            data['context'],\n",
    "            data['question'],\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            stride=128,\n",
    "            max_length=512\n",
    "        )\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        start_pos = data['start_pos'].to(device)\n",
    "        end_pos = data['end_pos'].to(device)\n",
    "        optim.zero_grad()\n",
    "        with autocast(): \n",
    "            outputs = train_model(**inputs, start_positions=start_pos, end_positions=end_pos)\n",
    "            loss = outputs.loss\n",
    "        scaler_object.scale(loss).backward()\n",
    "        batch_count += 1\n",
    "        if batch_count % acc_steps == 0:\n",
    "            scaler_object.step(optim)  \n",
    "            scaler_object.update()  \n",
    "            optim.zero_grad()   \n",
    "        loss_val = loss.item()\n",
    "        if str(loss_val) == 'nan':\n",
    "            loss_val = 0\n",
    "        t_loss += loss_val\n",
    "    if batch_count % acc_steps != 0:\n",
    "        scaler_object.step(optim)  \n",
    "        scaler_object.update() \n",
    "        optim.zero_grad() \n",
    "    return t_loss / len(data_ld)\n",
    "\n",
    "\n",
    "def test_fn(test_model, data_ld, optim, device, tokenizer):\n",
    "    \"\"\"\n",
    "    Function to evaluate the performance of a model on test data.\n",
    "\n",
    "    Args:\n",
    "        test_model (torch.nn.Module): The model to be evaluated.\n",
    "        data_ld (torch.utils.data.DataLoader): The data loader containing the test data.\n",
    "        optim (torch.optim.Optimizer): The optimizer used for training the model.\n",
    "        device (torch.device): The device on which the model and data should be loaded.\n",
    "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer used for tokenizing the input data.\n",
    "\n",
    "    Returns:\n",
    "        float: The average loss value over the test data.\n",
    "\n",
    "    \"\"\"\n",
    "    t_loss = 0.0\n",
    "    test_model.eval()\n",
    "    test_model.to(device)\n",
    "    scaler_object = GradScaler() \n",
    "    for data in data_ld:\n",
    "        inputs = tokenizer(\n",
    "            data['context'],\n",
    "            data['question'],\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            stride=128,\n",
    "            max_length=512\n",
    "        )\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        start_pos = data['start_pos'].to(device)\n",
    "        end_pos = data['end_pos'].to(device)\n",
    "        optim.zero_grad()\n",
    "        with autocast():  \n",
    "            outputs = test_model(**inputs, start_positions=start_pos, end_positions=end_pos)\n",
    "            loss = outputs.loss\n",
    "        loss_val = loss.item()\n",
    "        if str(loss_val) == 'nan':\n",
    "            loss_val = 0\n",
    "        t_loss += loss_val\n",
    "    return t_loss / len(data_ld)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f24e85e4-3efe-478e-b307-493364ff48b7",
   "metadata": {
    "id": "f24e85e4-3efe-478e-b307-493364ff48b7",
    "outputId": "ca45944b-f4a7-4786-9ced-f094997e0a92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch 1 , train loss 5.6710381880402565, test loss 5.692981338500976\n",
      "Epoch 2 , train loss 5.431648567318916, test loss 5.71663028717041\n",
      "Epoch 3 , train loss 5.215241692960262, test loss 5.727792015075684\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code snippet trains a BERT-based Question Answering model using the SQuAD dataset.\n",
    "It initializes the device based on the availability of CUDA, prints the device type,\n",
    "loads the BERT tokenizer and model, sets up the optimizer and scheduler, and moves the model to the device.\n",
    "Then, it trains the model for the specified number of epochs, printing the training and testing loss for each epoch.\n",
    "The learning rate is reduced on a plateau using the testing loss as a metric.\n",
    "\"\"\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', max_length=512)\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_fn(model, train_dl, optimizer, device, acc_steps=2, tokenizer=tokenizer)\n",
    "    test_loss = test_fn(model, test_dl, optimizer, device, tokenizer=tokenizer)\n",
    "    print(f'Epoch {epoch+1}, train loss {train_loss}, test loss {test_loss}')\n",
    "    scheduler.step(test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4d7fda2-1eff-4d24-9740-60177854f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting_answer(model, tokenizer, context, question):\n",
    "    \"\"\"\n",
    "    Predicts the answer to a given question based on the context using a pre-trained model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The pre-trained model used for prediction.\n",
    "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer used to tokenize the input.\n",
    "        context (str): The context in which the question is asked.\n",
    "        question (str): The question to be answered.\n",
    "\n",
    "    Returns:\n",
    "        str: The predicted answer to the question.\n",
    "\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(question, context, return_tensors='pt', padding=True, truncation=True)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    input_ids = inputs['input_ids'].squeeze()\n",
    "    output = model(**inputs)\n",
    "    start_index = torch.argmax(output.start_logits)\n",
    "    end_index = torch.argmax(output.end_logits) + 1\n",
    "    if end_index < start_index:\n",
    "        start_index, end_index = end_index, start_index\n",
    "    predicted_answer = tokenizer.decode(input_ids[start_index:end_index])\n",
    "    return predicted_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6909a416-735e-42d0-8aee-ec99fd42e005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american football conference\n"
     ]
    }
   ],
   "source": [
    "para = \"super bowl fifty was an american football game to determine the champion of the national football league nfl for the twenty fifteen season. the american football conference a f c c champion denver broncos defeated the national football conference n f c c champion carolina panthers twenty four to ten to earn their third super bowl title. the game was played on february seventh twenty sixteen and levis stadium in the san francisco bay area santa clara california. as this was the fiftieth super bowl the league emphasized the golden anniversary with various goldsteins initiatives as well as temporarily suspending the tradition of naming each super bowl game with roman numerals under which they gain would have been known as super bowl l sell that the logo could prominently featured the arabic numerals fifty.\"\n",
    "ques = \"What does AFC stand for?\"\n",
    "predicted_answer = predicting_answer(model, tokenizer, para, ques)\n",
    "print(predicted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21de52c7-f513-4074-a01c-4a836ea33244",
   "metadata": {
    "id": "21de52c7-f513-4074-a01c-4a836ea33244",
    "outputId": "aba95ade-42a0-4f4f-8bfd-10e190dcaa71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 , train loss 5.75785543769598, test loss 5.828500843048095\n",
      "Epoch 2 , train loss 5.645928509533405, test loss 5.828914890289306\n",
      "Epoch 3 , train loss 5.3587766364216805, test loss 5.79552303314209\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code snippet trains a DistilBERT model for question answering using the SQuAD dataset.\n",
    "It initializes a DistilBertTokenizer and a DistilBertForQuestionAnswering model.\n",
    "The optimizer used is AdamW with a specified learning rate.\n",
    "The model is then moved to the specified device (e.g., GPU) for training.\n",
    "The training loop runs for the specified number of epochs.\n",
    "In each epoch, the model is trained using the train_fn function and evaluated using the test_fn function.\n",
    "The train and test losses are printed for each epoch.\n",
    "The learning rate scheduler is updated based on the test loss.\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased', max_length=512)\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-cased')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model = model.to(device)\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_fn(model, train_dl, optimizer, device, acc_steps=2)\n",
    "    test_loss = test_fn(model, test_dl, optimizer, device)\n",
    "    print(f'Epoch {epoch+1}, train loss {train_loss}, test loss {test_loss}')\n",
    "    scheduler.step(test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "PT_4jbQv7bvY",
   "metadata": {
    "id": "PT_4jbQv7bvY"
   },
   "outputs": [],
   "source": [
    "def predict_answer(model, tokenizer, context, question):\n",
    "    \"\"\"\n",
    "    Predicts the answer to a given question based on the context using a pre-trained model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The pre-trained model used for prediction.\n",
    "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer used to tokenize the input.\n",
    "        context (str): The context in which the question is asked.\n",
    "        question (str): The question to be answered.\n",
    "\n",
    "    Returns:\n",
    "        str: The predicted answer to the question.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(question, context, return_tensors='pt', padding=True, truncation=True)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    input_ids = inputs['input_ids'].squeeze()\n",
    "    output = model(**inputs)\n",
    "    start_index = torch.argmax(output.start_logits)\n",
    "    end_index = torch.argmax(output.end_logits) + 1\n",
    "    if end_index < start_index:\n",
    "        start_index, end_index = end_index, start_index\n",
    "    predicted_answer = tokenizer.decode(input_ids[start_index:end_index])\n",
    "    return predicted_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de09e08e-a379-4d2a-adbe-218a9844173b",
   "metadata": {
    "id": "de09e08e-a379-4d2a-adbe-218a9844173b",
    "outputId": "2b5365c0-5050-4334-a5a1-30c975f7fd47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american football conference\n"
     ]
    }
   ],
   "source": [
    "para = \"super bowl fifty was an american football game to determine the champion of the national football league nfl for the twenty fifteen season. the american football conference a f c c champion denver broncos defeated the national football conference n f c c champion carolina panthers twenty four to ten to earn their third super bowl title. the game was played on february seventh twenty sixteen and levis stadium in the san francisco bay area santa clara california. as this was the fiftieth super bowl the league emphasized the golden anniversary with various goldsteins initiatives as well as temporarily suspending the tradition of naming each super bowl game with roman numerals under which they gain would have been known as super bowl l sell that the logo could prominently featured the arabic numerals fifty.\"\n",
    "ques = \"What does AFC stand for?\"\n",
    "paragraph = \"super bowl fifty was an american football game to determine the champion of the national football league nfl for the twenty fifteen season. the american football conference a f c c champion denver broncos defeated the national football conference n f c c champion carolina panthers twenty four to ten to earn their third super bowl title. the game was played on february seventh twenty sixteen and levis stadium in the san francisco bay area santa clara california. as this was the fiftieth super bowl the league emphasized the golden anniversary with various goldsteins initiatives as well as temporarily suspending the tradition of naming each super bowl game with roman numerals under which they gain would have been known as super bowl l sell that the logo could prominently featured the arabic numerals fifty.\"\n",
    "question = \"What does AFC stand for?\"\n",
    "\n",
    "predicted_answer = predicting_answer(model, tokenizer, paragraph, question)\n",
    "print(predicted_answer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
